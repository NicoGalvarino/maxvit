{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#0.-Import-libraries\" data-toc-modified-id=\"0.-Import-libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>0. Import libraries</a></span></li><li><span><a href=\"#1.-Benchmark-inference-time\" data-toc-modified-id=\"1.-Benchmark-inference-time-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>1. Benchmark inference time</a></span></li><li><span><a href=\"#2.-Inference-on-images\" data-toc-modified-id=\"2.-Inference-on-images-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>2. Inference on images</a></span></li><li><span><a href=\"#3.-Directly-inference-on-higher-resolution.\" data-toc-modified-id=\"3.-Directly-inference-on-higher-resolution.-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>3. Directly inference on higher resolution.</a></span></li><li><span><a href=\"#4.-Inference-local-uploads.\" data-toc-modified-id=\"4.-Inference-local-uploads.-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>4. Inference local uploads.</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddJ96ROaSky7"
   },
   "source": [
    "# MaxViT Tutotial\n",
    "\n",
    "**Note**: Please connect to a GPU runtime instance. Make sure tensorflow can be imported.\n",
    "\n",
    "\n",
    "<table align=\"left\"><td>\n",
    "  <a target=\"_blank\"  href=\"https://github.com/google-research/maxvit/blob/main/MaxViT_tutorial.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on github\n",
    "  </a>\n",
    "</td><td>\n",
    "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/google-research/maxvit/blob/master/MaxViT_tutorial.ipynb\">\n",
    "    <img width=32px src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "</td></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrnMscR5S4pU"
   },
   "source": [
    "## 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "0lyz-6kXSG7X"
   },
   "outputs": [],
   "source": [
    "#@title Import libs\n",
    "import time\n",
    "from IPython import display\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "import tensorflow_datasets as tfds\n",
    "!git clone https://github.com/google-research/maxvit\n",
    "%cd /content/maxvit\n",
    "# set up module\n",
    "!python setup.py install\n",
    "\n",
    "# imports\n",
    "import maxvit.models.hparams as hparams\n",
    "import maxvit.models.maxvit as layers\n",
    "\n",
    "# Checkpoints location\n",
    "CKPTS_DIRS = {\n",
    "    'MaxViTTiny_i1k_224': 'gs://gresearch/maxvit/ckpts/maxvittiny/i1k/224',\n",
    "    'MaxViTTiny_i1k_384': 'gs://gresearch/maxvit/ckpts/maxvittiny/i1k/384',\n",
    "    'MaxViTTiny_i1k_512': 'gs://gresearch/maxvit/ckpts/maxvittiny/i1k/512',\n",
    "    'MaxViTSmall_i1k_224': 'gs://gresearch/maxvit/ckpts/maxvitsmall/i1k/224',\n",
    "    'MaxViTSmall_i1k_384': 'gs://gresearch/maxvit/ckpts/maxvitsmall/i1k/384',\n",
    "    'MaxViTSmall_i1k_512': 'gs://gresearch/maxvit/ckpts/maxvitsmall/i1k/512',\n",
    "    'MaxViTBase_i1k_224': 'gs://gresearch/maxvit/ckpts/maxvitbase/i1k/224',\n",
    "    'MaxViTBase_i1k_384': 'gs://gresearch/maxvit/ckpts/maxvitbase/i1k/384',\n",
    "    'MaxViTBase_i1k_512': 'gs://gresearch/maxvit/ckpts/maxvitbase/i1k/512',\n",
    "    'MaxViTBase_i21k_i1k_224': None,\n",
    "    'MaxViTBase_i21k_i1k_384': 'gs://gresearch/maxvit/ckpts/maxvitbase/i21k_i1k/384',\n",
    "    'MaxViTBase_i21k_i1k_512': 'gs://gresearch/maxvit/ckpts/maxvitbase/i21k_i1k/512',\n",
    "    'MaxViTLarge_i1k_224': 'gs://gresearch/maxvit/ckpts/maxvitlarge/i1k/224',\n",
    "    'MaxViTLarge_i1k_384': 'gs://gresearch/maxvit/ckpts/maxvitlarge/i1k/384',\n",
    "    'MaxViTLarge_i1k_512': 'gs://gresearch/maxvit/ckpts/maxvitlarge/i1k/512',\n",
    "    'MaxViTLarge_i21k_i1k_224': None,\n",
    "    'MaxViTLarge_i21k_i1k_384': 'gs://gresearch/maxvit/ckpts/maxvitlarge/i21k_i1k/384',\n",
    "    'MaxViTLarge_i21k_i1k_512': 'gs://gresearch/maxvit/ckpts/maxvitlarge/i21k_i1k/512',\n",
    "    'MaxViTXLarge_i21k_i1k_224': None,\n",
    "    'MaxViTXLarge_i21k_i1k_384': 'gs://gresearch/maxvit/ckpts/maxvitxlarge/i21k_i1k/384',\n",
    "    'MaxViTXLarge_i21k_i1k_512': 'gs://gresearch/maxvit/ckpts/maxvitxlarge/i21k_i1k/512',\n",
    "}\n",
    "\n",
    "DATASET_MAP = {\n",
    "    'ImageNet-1K': 'i1k', \n",
    "    'ImageNet-21K': 'i21k_i1k',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_ty3IU1TZm2"
   },
   "source": [
    "## 1. Benchmark inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ps7Fi33JTdUa",
    "outputId": "399cb580-b282-4b6c-d980-852d9b82f340"
   },
   "outputs": [],
   "source": [
    "#@title Set model and params\n",
    "\n",
    "MODEL_NAME = \"MaxViTTiny\" #@param [\"MaxViTTiny\", \"MaxViTSmall\", \"MaxViTBase\", \"MaxViTLarge\"] {type:\"string\"}\n",
    "IMAGE_SIZE = \"224\" #@param [224, 384, 512] {type:\"string\"}\n",
    "BATCH_SIZE = 16 #@param {type:\"integer\"}\n",
    "MIXED_PRECISION = True #@param {type:\"boolean\"}\n",
    "\n",
    "IMAGE_SIZE = int(IMAGE_SIZE)\n",
    "\n",
    "\n",
    "class MaxViTModel(tf.keras.Model):\n",
    "  \"\"\"class to build MaxViT family model.\"\"\"\n",
    "  def __init__(self,\n",
    "               model_name='',\n",
    "               model_input_size=224,\n",
    "               input_specs=tf.keras.layers.InputSpec(\n",
    "                   shape=[None, None, None, 3]),\n",
    "               training=True):\n",
    "    \"\"\"VisionTransformer initialization function.\"\"\"\n",
    "    inputs = tf.keras.Input(shape=input_specs.shape[1:])\n",
    "    config = hparams.lookup(model_name)\n",
    "\n",
    "    if model_input_size == 224:\n",
    "      config.model.window_size = 7\n",
    "      config.model.grid_size = 7\n",
    "      config.model.scale_ratio = None\n",
    "    elif model_input_size == 384:\n",
    "      config.model.window_size = 12\n",
    "      config.model.grid_size = 12\n",
    "      config.model.scale_ratio = '384/224'\n",
    "    elif model_input_size == 512:\n",
    "      config.model.window_size = 16\n",
    "      config.model.grid_size = 16\n",
    "      config.model.scale_ratio = '512/224'\n",
    "\n",
    "    model = layers.MaxViT(config.model)\n",
    "    out = model(inputs, training=training)\n",
    "\n",
    "    super(MaxViTModel, self).__init__(inputs=inputs, outputs=out)\n",
    "\n",
    "\n",
    "def build_tf2_model():\n",
    "  \"\"\"Build the tf2 model.\"\"\"\n",
    "  if MIXED_PRECISION:\n",
    "    # Use 'mixed_float16' if running on GPUs.\n",
    "    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "    tf.keras.mixed_precision.set_global_policy(policy)\n",
    "  model = MaxViTModel(model_name=MODEL_NAME,\n",
    "                      model_input_size=IMAGE_SIZE,\n",
    "                      input_specs=tf.keras.layers.InputSpec(\n",
    "                      shape=[BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3]),\n",
    "                      training=False)\n",
    "  return model\n",
    "\n",
    "\n",
    "def run_tf_benchmark():\n",
    "  \"\"\"Run benchmark.\"\"\"\n",
    "  model = build_tf2_model()\n",
    "  imgs = tf.ones((BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3), dtype=tf.float16)\n",
    "\n",
    "  @tf.function\n",
    "  def f(x):\n",
    "    return model(x, training=False)\n",
    "\n",
    "  print('starting warmup.')\n",
    "  for _ in range(10):  # warmup runs.\n",
    "    f(imgs)\n",
    "\n",
    "  print('start benchmark.')\n",
    "  start = time.perf_counter()\n",
    "  for _ in range(10):\n",
    "    f(imgs)\n",
    "  end = time.perf_counter()\n",
    "  inference_time = (end - start) / 10\n",
    "\n",
    "  print('Per batch inference time: ', inference_time)\n",
    "  print('FPS: ', BATCH_SIZE / inference_time)\n",
    "\n",
    "run_tf_benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nYfko9gZ5Xw"
   },
   "source": [
    "## 2. Inference on images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ezdcUOq2Z82E"
   },
   "outputs": [],
   "source": [
    "#@title Set model and params (ImageNet-1K models)\n",
    "\n",
    "MODEL_NAME = \"MaxViTBase\" #@param [\"MaxViTTiny\", \"MaxViTSmall\", \"MaxViTBase\", \"MaxViTLarge\"] {type:\"string\"}\n",
    "TRAIN_SET = \"ImageNet-1K\" #@param [\"ImageNet-1K\"] {type:\"string\"}\n",
    "TRAIN_IMAGE_SIZE = \"224\" #@param [224, 384, 512] {type:\"string\"}\n",
    "MIXED_PRECISION = False #@param {type:\"boolean\"}\n",
    "\n",
    "CKPT_DIR = CKPTS_DIRS[f'{MODEL_NAME}_{DATASET_MAP[TRAIN_SET]}_{TRAIN_IMAGE_SIZE}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "id": "Kll3az4_kbBq",
    "outputId": "f38add49-4a26-4279-9983-af36a1f40cc5"
   },
   "outputs": [],
   "source": [
    "#@title Inference on example image\n",
    "import maxvit.models.eval_ckpt as eval_ckpt\n",
    "\n",
    "#@markdown ### Enter a file path:\n",
    "file_path = \"https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG\" #@param {type:\"string\"}\n",
    "INFER_IMAGE_SIZE = \"224\" #@param [224, 384, 448, 512, 672, 768, 896, 1024] {type:\"string\"}\n",
    "\n",
    "# Download label map file and image\n",
    "labels_map_file = 'gs://cloud-tpu-checkpoints/efficientnet/eval_data/labels_map.json'\n",
    "image_file = 'panda.jpg'\n",
    "\n",
    "!wget {file_path} -O {image_file}\n",
    "\n",
    "image_files = [image_file]\n",
    "\n",
    "eval_driver = eval_ckpt.MaxViTDriver(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_input_size=TRAIN_IMAGE_SIZE,\n",
    "    batch_size=1,\n",
    "    image_size=int(INFER_IMAGE_SIZE),\n",
    "    include_background_label=False,\n",
    "    advprop_preprocessing=False,)\n",
    "\n",
    "print(f\"Input image:\")\n",
    "display.display(display.Image(image_file, width=INFER_IMAGE_SIZE))\n",
    "\n",
    "print(f\"MaxViT prediction:\")\n",
    "pred_idx, pred_prob = eval_driver.eval_example_images(\n",
    "    CKPT_DIR, image_files, labels_map_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "atmiEcgVASsW"
   },
   "outputs": [],
   "source": [
    "#@title Using ImageNet-21K pre-trained models\n",
    "\n",
    "MODEL_NAME = \"MaxViTBase\" #@param [\"MaxViTBase\", \"MaxViTLarge\", \"MaxViTXLarge\"] {type:\"string\"}\n",
    "TRAIN_SET = \"ImageNet-21K\" #@param [\"ImageNet-21K\"] {type:\"string\"}\n",
    "TRAIN_IMAGE_SIZE = \"384\" #@param [384, 512] {type:\"string\"}\n",
    "MIXED_PRECISION = False #@param {type:\"boolean\"}\n",
    "\n",
    "CKPT_DIR = CKPTS_DIRS[f'{MODEL_NAME}_{DATASET_MAP[TRAIN_SET]}_{TRAIN_IMAGE_SIZE}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "id": "NWgFrh77AVy6",
    "outputId": "8b5821bc-e290-41ff-f1ba-a131552e002e"
   },
   "outputs": [],
   "source": [
    "#@title Inference on example image\n",
    "import maxvit.models.eval_ckpt as eval_ckpt\n",
    "\n",
    "#@markdown ### Enter a file path:\n",
    "file_path = \"https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG\" #@param {type:\"string\"}\n",
    "INFER_IMAGE_SIZE = \"384\" #@param [224, 384, 448, 512, 672, 768, 896, 1024] {type:\"string\"}\n",
    "\n",
    "# Download label map file and image\n",
    "labels_map_file = 'gs://cloud-tpu-checkpoints/efficientnet/eval_data/labels_map.json'\n",
    "image_file = 'panda.jpg'\n",
    "\n",
    "!wget {file_path} -O {image_file}\n",
    "\n",
    "image_files = [image_file]\n",
    "\n",
    "eval_driver = eval_ckpt.MaxViTDriver(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_input_size=TRAIN_IMAGE_SIZE,\n",
    "    batch_size=1,\n",
    "    image_size=int(INFER_IMAGE_SIZE),\n",
    "    include_background_label=False,\n",
    "    legacy_preprocessing=False,)\n",
    "\n",
    "print(f\"Input image:\")\n",
    "display.display(display.Image(image_file, width=INFER_IMAGE_SIZE))\n",
    "\n",
    "print(f\"MaxViT prediction:\")\n",
    "pred_idx, pred_prob = eval_driver.eval_example_images(\n",
    "    CKPT_DIR, image_files, labels_map_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtFHFH8w4y1p"
   },
   "source": [
    "## 3. Directly inference on higher resolution.\n",
    "\n",
    "Note INFER_IMAGE_SIZE needs to be multipliers of TRAIN_IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "8Wa59iaS5EJz"
   },
   "outputs": [],
   "source": [
    "#@title Set model and params\n",
    "\n",
    "MODEL_NAME = \"MaxViTTiny\" #@param [\"MaxViTTiny\", \"MaxViTSmall\", \"MaxViTBase\", \"MaxViTLarge\"] {type:\"string\"}\n",
    "TRAIN_SET = \"ImageNet-1K\" #@param [\"ImageNet-1K\"] {type:\"string\"}\n",
    "TRAIN_IMAGE_SIZE = \"224\" #@param [224, 384, 512] {type:\"string\"}\n",
    "MIXED_PRECISION = False #@param {type:\"boolean\"}\n",
    "\n",
    "CKPT_DIR = CKPTS_DIRS[f'{MODEL_NAME}_{DATASET_MAP[TRAIN_SET]}_{TRAIN_IMAGE_SIZE}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "id": "uWAAi2uw5Hki",
    "outputId": "44eb548f-6958-47c8-b707-28c97c7223b3"
   },
   "outputs": [],
   "source": [
    "#@title Inference on example image\n",
    "import maxvit.models.eval_ckpt as eval_ckpt\n",
    "\n",
    "#@markdown ### Enter a file path:\n",
    "file_path = \"https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG\" #@param {type:\"string\"}\n",
    "INFER_IMAGE_SIZE = \"672\" #@param [224, 384, 448, 512, 672, 768, 896, 1024] {type:\"string\"}\n",
    "\n",
    "# Download label map file and image\n",
    "labels_map_file = 'gs://cloud-tpu-checkpoints/efficientnet/eval_data/labels_map.json'\n",
    "image_file = 'panda.jpg'\n",
    "\n",
    "!wget {file_path} -O {image_file}\n",
    "\n",
    "image_files = [image_file]\n",
    "\n",
    "eval_driver = eval_ckpt.MaxViTDriver(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_input_size=TRAIN_IMAGE_SIZE,\n",
    "    batch_size=1,\n",
    "    image_size=int(INFER_IMAGE_SIZE),\n",
    "    include_background_label=False,\n",
    "    advprop_preprocessing=False,)\n",
    "\n",
    "print(f\"Input image:\")\n",
    "display.display(display.Image(image_file, width=INFER_IMAGE_SIZE))\n",
    "\n",
    "print(f\"MaxViT prediction:\")\n",
    "pred_idx, pred_prob = eval_driver.eval_example_images(\n",
    "    CKPT_DIR, image_files, labels_map_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjPgxuLA5M92"
   },
   "source": [
    "## 4. Inference local uploads.\n",
    "\n",
    "Note some image formats are not supported by Tensorflow IO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "oeM4qBp46BSJ"
   },
   "outputs": [],
   "source": [
    "#@title Set model and params\n",
    "\n",
    "MODEL_NAME = \"MaxViTTiny\" #@param [\"MaxViTTiny\", \"MaxViTSmall\", \"MaxViTBase\", \"MaxViTLarge\"] {type:\"string\"}\n",
    "TRAIN_SET = \"ImageNet-1K\" #@param [\"ImageNet-1K\"] {type:\"string\"}\n",
    "TRAIN_IMAGE_SIZE = \"224\" #@param [224, 384, 512] {type:\"string\"}\n",
    "MIXED_PRECISION = False #@param {type:\"boolean\"}\n",
    "\n",
    "CKPT_DIR = CKPTS_DIRS[f'{MODEL_NAME}_{DATASET_MAP[TRAIN_SET]}_{TRAIN_IMAGE_SIZE}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "JBBBuwU36-tQ",
    "outputId": "dd699572-efdb-400f-ba04-5169a45909e6"
   },
   "outputs": [],
   "source": [
    "#@title Inference on uploaded image\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "INFER_IMAGE_SIZE = \"224\" #@param [224, 384, 448, 512, 672, 768, 896, 1024] {type:\"string\"}\n",
    "\n",
    "\n",
    "save_path = './' + list(uploaded.keys())[0]\n",
    "with open(save_path, \"wb\") as f:\n",
    "  f.write(list(uploaded.values())[0])\n",
    "\n",
    "image_files = [save_path]\n",
    "\n",
    "eval_driver = eval_ckpt.MaxViTDriver(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_input_size=TRAIN_IMAGE_SIZE,\n",
    "    batch_size=1,\n",
    "    image_size=int(INFER_IMAGE_SIZE),\n",
    "    include_background_label=False,\n",
    "    advprop_preprocessing=False,)\n",
    "\n",
    "print(f\"Input image:\")\n",
    "display.display(display.Image(save_path, width=INFER_IMAGE_SIZE))\n",
    "\n",
    "print(f\"MaxViT prediction:\")\n",
    "pred_idx, pred_prob = eval_driver.eval_example_images(\n",
    "    CKPT_DIR, image_files, labels_map_file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
